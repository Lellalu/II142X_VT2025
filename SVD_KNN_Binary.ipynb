{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a1576cf2-3d33-4bab-b0ab-e4334cafd779",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import numpy as np\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4cff2028-3f64-4285-8396-41163b4f30be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete matrix shape: (197000, 3)\n",
      "Number of 1s (investments): 5281\n",
      "Number of 0s (no investments): 191719\n",
      "Matrix sparsity: 97.32%\n",
      "Best parameters: {'n_epochs': 80, 'lr_all': 0.005, 'reg_all': 0.004}\n",
      "SVD model with binary data:\n",
      "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
      "RMSE: 0.1504\n",
      "RMSE: 0.1504384074603101\n",
      "MAE: Mean Absolute Error. Lower values mean better accuracy.\n",
      "MAE:  0.0450\n",
      "MAE: 0.04503373910130982\n",
      "\n",
      "Top 5 recommended baskets for user 1001:\n",
      "→ Financial World  nu funds (expected rating: 0.28)\n",
      "→ Australian Health (expected rating: 0.20)\n",
      "→ Consumer Global INDEX (expected rating: 0.17)\n",
      "→ Swedish climbers (expected rating: 0.14)\n",
      "→ Real estate Europe (expected rating: 0.12)\n"
     ]
    }
   ],
   "source": [
    "#USING MANUAL TRAIN-TEST DATASET DIVISION: 80% user data used for tarining, 20% user used for test\n",
    "# Data loading\n",
    "investments = pd.read_csv('syntheticDataGenerators/investment/invest_data.csv', sep=';')\n",
    "baskets = pd.read_csv('data/company_basket.csv', sep=';')\n",
    "\n",
    "# Get all unique users and baskets\n",
    "unique_users = investments['user_id'].unique()\n",
    "unique_baskets = baskets['basket_name'].unique()\n",
    "\n",
    "# Create an empty dataframe with all possible user-basket combinations\n",
    "all_combinations = []\n",
    "for user in unique_users:\n",
    "    for basket in unique_baskets:\n",
    "        all_combinations.append({'user_id': user, 'basket_name': basket})\n",
    "\n",
    "# Convert to DataFrame\n",
    "complete_matrix = pd.DataFrame(all_combinations)\n",
    "\n",
    "# Create a set of (user_id, basket_name) tuples for quick lookup\n",
    "invested_pairs = set(zip(investments['user_id'], investments['basket_name']))\n",
    "\n",
    "# Add binary rating column (1 if user invested in basket, 0 otherwise)\n",
    "complete_matrix['binary_rating'] = complete_matrix.apply(\n",
    "    lambda row: 1 if (row['user_id'], row['basket_name']) in invested_pairs else 0, \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# Verify our matrix\n",
    "print(f\"Complete matrix shape: {complete_matrix.shape}\")\n",
    "print(f\"Number of 1s (investments): {complete_matrix['binary_rating'].sum()}\")\n",
    "print(f\"Number of 0s (no investments): {len(complete_matrix) - complete_matrix['binary_rating'].sum()}\")\n",
    "print(f\"Matrix sparsity: {(1 - complete_matrix['binary_rating'].mean()) * 100:.2f}%\")\n",
    "\n",
    "# Now use these binary ratings with Surprise\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "# Get unique list of users\n",
    "sorted_users = np.sort(unique_users)\n",
    "\n",
    "# Calculate the split point (80% of users)\n",
    "split_idx = int(len(sorted_users) * 0.8)\n",
    "\n",
    "# Get training and testing user sets\n",
    "train_users = sorted_users[:split_idx]\n",
    "test_users = sorted_users[split_idx:]\n",
    "\n",
    "# Filter data by user groups\n",
    "train_data = complete_matrix[complete_matrix['user_id'].isin(train_users)]\n",
    "test_data = complete_matrix[complete_matrix['user_id'].isin(test_users)]\n",
    "\n",
    "# Now create the Surprise datasets with the binary ratings\n",
    "trainset = Dataset.load_from_df(\n",
    "    train_data[['user_id', 'basket_name', 'binary_rating']], \n",
    "    reader\n",
    ").build_full_trainset()\n",
    "\n",
    "# For the testset, we need to convert it to the proper format for testing\n",
    "# (user, item, rating) tuples\n",
    "testset = [(uid, iid, r) for uid, iid, r in \n",
    "           test_data[['user_id', 'basket_name', 'binary_rating']].itertuples(index=False)]\n",
    "\n",
    "# Optional: Grid search for hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"n_epochs\": [10, 20, 40, 80], \n",
    "    \"lr_all\": [0.0005, 0.001, 0.002, 0.005], \n",
    "    \"reg_all\": [0.0005, 0.001, 0.002, 0.004]\n",
    "}\n",
    "\n",
    "# Create a full dataset for grid search\n",
    "full_dataset = Dataset.load_from_df(\n",
    "    complete_matrix[['user_id', 'basket_name', 'binary_rating']], \n",
    "    reader\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"mae\"], cv=3, refit=True)\n",
    "gs.fit(full_dataset)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = gs.best_params[\"mae\"]\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Initialize SVD with best parameters\n",
    "model_SVD = SVD(\n",
    "    n_epochs=best_params[\"n_epochs\"],\n",
    "    lr_all=best_params[\"lr_all\"],\n",
    "    reg_all=best_params[\"reg_all\"]\n",
    ")\n",
    "# Alternative: Use default parameters\n",
    "# model_SVD = SVD()\n",
    "\n",
    "# Fit the model\n",
    "model_SVD.fit(trainset)\n",
    "\n",
    "# Test model\n",
    "predictions = model_SVD.test(testset)\n",
    "\n",
    "# Evaluate with RMSE and MAE\n",
    "print(\"SVD model with binary data:\")\n",
    "print(\"RMSE: Root Mean Squared Error. Lower values mean better accuracy.\")\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(\"MAE: Mean Absolute Error. Lower values mean better accuracy.\")\n",
    "mae = accuracy.mae(predictions)\n",
    "print(f\"MAE: {mae}\")\n",
    "\n",
    "# Make recommendation to a specific user\n",
    "user_id = 1001  # Choose a user ID to make recommendations for\n",
    "# Get baskets the user has already invested in\n",
    "already_invested = investments[investments['user_id'] == user_id]['basket_name'].unique()\n",
    "# Get baskets the user hasn't invested in yet\n",
    "baskets_to_predict = [b for b in unique_baskets if b not in already_invested]\n",
    "\n",
    "# Predict user's interests for new baskets\n",
    "user_predictions = [model_SVD.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "# Sort by predicted rating (highest first)\n",
    "top_recommendations = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:5]\n",
    "\n",
    "print(f\"\\nTop 5 recommended baskets for user {user_id}:\")\n",
    "for pred in top_recommendations:\n",
    "    print(f\"→ {pred.iid} (expected rating: {pred.est:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a5e1cf7e-b44f-4df6-8b30-58aba479c218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.trainset.Trainset at 0x1226a6f90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "17db24b7-04ff-46d6-9c11-f20e25e0b7a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@1: 0.0000\n",
      "Recall@1: 0.0000\n",
      "F1@1: 0.0000\n",
      "Precision@2: 0.3875\n",
      "Recall@2: 0.1502\n",
      "F1@2: 0.2143\n",
      "Precision@5: 0.3070\n",
      "Recall@5: 0.2947\n",
      "F1@5: 0.2966\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store precision and recall values\n",
    "precision_at_k = collections.defaultdict(list)\n",
    "recall_at_k = collections.defaultdict(list)\n",
    "f1_at_k = collections.defaultdict(list)\n",
    "\n",
    "# Get all unique test users\n",
    "test_user_ids = np.unique([uid for uid, _, _ in testset])\n",
    "\n",
    "# Get all unique baskets\n",
    "all_baskets = unique_baskets  # Use the unique_baskets we defined earlier\n",
    "\n",
    "# For each user in the test set\n",
    "for user_id in test_user_ids:    \n",
    "    # Find baskets this user has invested in (binary_rating=1) in test data (ground truth)\n",
    "    user_test_data = test_data[test_data['user_id'] == user_id]\n",
    "    user_positive_test_baskets = set(user_test_data[user_test_data['binary_rating'] == 1]['basket_name'])\n",
    "    \n",
    "    # If no positive test baskets, skip this user\n",
    "    if len(user_positive_test_baskets) == 0:\n",
    "        continue\n",
    "        \n",
    "    # Find baskets the user has already invested in (from both train and test data)\n",
    "    user_invested_baskets = set(\n",
    "        investments[investments['user_id'] == user_id]['basket_name']\n",
    "    )\n",
    "    \n",
    "    # Find baskets to predict for (all baskets minus those already invested in)\n",
    "    # Comment out the following line if you want to recommend any basket, including those the user already invested in\n",
    "    # baskets_to_predict = [b for b in all_baskets if b not in user_invested_baskets]\n",
    "    \n",
    "    # Or predict for all baskets\n",
    "    baskets_to_predict = [b for b in all_baskets]\n",
    "    \n",
    "    # Make predictions for all baskets\n",
    "    user_predictions = [model_SVD.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "    sorted_predictions = sorted(user_predictions, key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Calculate precision and recall at different k values\n",
    "    for k in [2, 5, 10]:\n",
    "        # Ensure k doesn't exceed number of predictions\n",
    "        effective_k = min(k, len(sorted_predictions))\n",
    "        \n",
    "        # Skip if no predictions\n",
    "        if effective_k == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get top-k recommended baskets\n",
    "        top_k_recs = [pred.iid for pred in sorted_predictions[:effective_k]]\n",
    "        \n",
    "        # Calculate relevant items among top-k recommendations (positive baskets in test set)\n",
    "        true_positives = len(set(top_k_recs) & user_positive_test_baskets)\n",
    "        \n",
    "        # Precision = relevant recommended / all recommended\n",
    "        precision = true_positives / effective_k\n",
    "        \n",
    "        # Recall = relevant recommended / all relevant\n",
    "        recall = true_positives / len(user_positive_test_baskets) \n",
    "\n",
    "        # F1 score = 2 * (precision * recall) / (precision + recall)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        precision_at_k[k].append(precision)\n",
    "        recall_at_k[k].append(recall)\n",
    "        f1_at_k[k].append(f1)\n",
    "\n",
    "# Calculate average precision and recall\n",
    "for k in [1, 2, 5]:\n",
    "    avg_precision = np.mean(precision_at_k[k]) if precision_at_k[k] else 0\n",
    "    avg_recall = np.mean(recall_at_k[k]) if recall_at_k[k] else 0\n",
    "    avg_f1 = np.mean(f1_at_k[k]) if f1_at_k[k] else 0\n",
    "    \n",
    "    print(f\"Precision@{k}: {avg_precision:.4f}\")\n",
    "    print(f\"Recall@{k}: {avg_recall:.4f}\")\n",
    "    print(f\"F1@{k}: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2ef3caa-ed20-478d-b58e-a5332ccfac1e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNN model:\n",
      "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
      "RMSE: 0.1618\n",
      "MAE: Mean Absolute Error. Lower values mean better accuracy.\n",
      "MAE:  0.0522\n",
      "\n",
      "Topp 5 rekommenderade baskets för användare 1001:\n",
      "→ Financial World  nu funds (förväntad rating: 0.60)\n",
      "→ Tech online services World (förväntad rating: 0.20)\n",
      "→ Australia tech index (förväntad rating: 0.00)\n",
      "→ BIG INDEX Global (förväntad rating: 0.00)\n",
      "→ Real estate Europe (förväntad rating: 0.00)\n"
     ]
    }
   ],
   "source": [
    "# Train KNN-model\n",
    "model_KNN = KNNBasic(k=5)\n",
    "model_KNN.fit(trainset)\n",
    "\n",
    "# Test model\n",
    "predictions = model_KNN.test(testset)\n",
    "\n",
    "# Evaluate with RMSE, MAE and FCP\n",
    "print(\"KNN model:\")\n",
    "print(\"RMSE: Root Mean Squared Error. Lower values mean better accuracy.\")\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"MAE: Mean Absolute Error. Lower values mean better accuracy.\")\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "# Make recommendation to a specific user\n",
    "user_id = 1001\n",
    "all_baskets = investments['basket_name'].unique()\n",
    "already_invested = investments[investments['user_id'] == user_id]['basket_name'].unique()\n",
    "baskets_to_predict = [b for b in all_baskets if b not in already_invested]\n",
    "\n",
    "# Predict user's intresses for new baskets\n",
    "user_predictions = [model_KNN.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "top_recommendations = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:5]\n",
    "\n",
    "print(f\"\\nTopp 5 rekommenderade baskets för användare {user_id}:\")\n",
    "for pred in top_recommendations:\n",
    "    print(f\"→ {pred.iid} (förväntad rating: {pred.est:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e2277b1-bc9a-4734-939f-547263dcb018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@2: 0.0050\n",
      "Recall@2: 0.0023\n",
      "F1@2: 0.0031\n",
      "Precision@5: 0.0030\n",
      "Recall@5: 0.0028\n",
      "F1@5: 0.0028\n",
      "Precision@10: 0.0120\n",
      "Recall@10: 0.0237\n",
      "F1@10: 0.0158\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store precision and recall values\n",
    "precision_at_k = collections.defaultdict(list)\n",
    "recall_at_k = collections.defaultdict(list)\n",
    "f1_at_k = collections.defaultdict(list)\n",
    "\n",
    "# Get all unique test users\n",
    "test_user_ids = np.unique([uid for uid, _, _ in testset])\n",
    "\n",
    "# Get all unique baskets\n",
    "all_baskets = unique_baskets  # Use the unique_baskets we defined earlier\n",
    "\n",
    "# For each user in the test set\n",
    "for user_id in test_user_ids:    \n",
    "    # Find baskets this user has invested in (binary_rating=1) in test data (ground truth)\n",
    "    user_test_data = test_data[test_data['user_id'] == user_id]\n",
    "    user_positive_test_baskets = set(user_test_data[user_test_data['binary_rating'] == 1]['basket_name'])\n",
    "    \n",
    "    # If no positive test baskets, skip this user\n",
    "    if len(user_positive_test_baskets) == 0:\n",
    "        continue\n",
    "        \n",
    "    # Find baskets the user has already invested in (from both train and test data)\n",
    "    user_invested_baskets = set(\n",
    "        investments[investments['user_id'] == user_id]['basket_name']\n",
    "    )\n",
    "    \n",
    "    # Find baskets to predict for (all baskets minus those already invested in)\n",
    "    # Comment out the following line if you want to recommend any basket, including those the user already invested in\n",
    "    # baskets_to_predict = [b for b in all_baskets if b not in user_invested_baskets]\n",
    "    \n",
    "    # Or predict for all baskets\n",
    "    baskets_to_predict = [b for b in all_baskets]\n",
    "    \n",
    "    # Make predictions for all baskets\n",
    "    user_predictions = [model_KNN.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "    sorted_predictions = sorted(user_predictions, key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Calculate precision and recall at different k values\n",
    "    for k in [2, 5, 10]:\n",
    "        # Ensure k doesn't exceed number of predictions\n",
    "        effective_k = min(k, len(sorted_predictions))\n",
    "        \n",
    "        # Skip if no predictions\n",
    "        if effective_k == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get top-k recommended baskets\n",
    "        top_k_recs = [pred.iid for pred in sorted_predictions[:effective_k]]\n",
    "        \n",
    "        # Calculate relevant items among top-k recommendations (positive baskets in test set)\n",
    "        true_positives = len(set(top_k_recs) & user_positive_test_baskets)\n",
    "        \n",
    "        # Precision = relevant recommended / all recommended\n",
    "        precision = true_positives / effective_k\n",
    "        \n",
    "        # Recall = relevant recommended / all relevant\n",
    "        recall = true_positives / len(user_positive_test_baskets) \n",
    "\n",
    "        # F1 score = 2 * (precision * recall) / (precision + recall)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        precision_at_k[k].append(precision)\n",
    "        recall_at_k[k].append(recall)\n",
    "        f1_at_k[k].append(f1)\n",
    "\n",
    "# Calculate average precision and recall\n",
    "for k in [2, 5, 10]:\n",
    "    avg_precision = np.mean(precision_at_k[k]) if precision_at_k[k] else 0\n",
    "    avg_recall = np.mean(recall_at_k[k]) if recall_at_k[k] else 0\n",
    "    avg_f1 = np.mean(f1_at_k[k]) if f1_at_k[k] else 0\n",
    "    \n",
    "    print(f\"Precision@{k}: {avg_precision:.4f}\")\n",
    "    print(f\"Recall@{k}: {avg_recall:.4f}\")\n",
    "    print(f\"F1@{k}: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c030c92-0369-4479-9ddb-be9d5b32f2a4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
