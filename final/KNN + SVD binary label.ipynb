{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dc932a65-c611-4405-b567-e5a603b5dc88",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import numpy as np\n",
    "from surprise.model_selection import GridSearchCV\n",
    "import collections\n",
    "import os\n",
    "import collections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cda6859e-ae86-4640-acaf-787941e0ae76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'n_epochs': 40, 'lr_all': 0.005, 'reg_all': 0.004}\n",
      "\n",
      "SVD model with binary data:\n",
      "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
      "RMSE: 0.1140\n",
      "RMSE: 0.11397805102974332\n",
      "MAE: Mean Absolute Error. Lower values mean better accuracy.\n",
      "MAE:  0.0344\n",
      "MAE: 0.034359644808922736\n",
      "\n",
      "Top 5 recommended baskets for user 1001:\n",
      "→ Basket Food world 7 (predicted rating: 0.3828)\n",
      "→ Basket Well traded stocks (predicted rating: 0.2147)\n",
      "→ Basket Techs going upward (predicted rating: 0.1396)\n",
      "→ Basket Software in Sweden (predicted rating: 0.1228)\n",
      "→ Basket Sustainable electric equipment (predicted rating: 0.1212)\n",
      "\n",
      "Testing recommendation function:\n",
      "Recommendations for user 1001:\n",
      "→ Basket Food world 7 (predicted rating: 0.3828)\n",
      "→ Basket Well traded stocks (predicted rating: 0.2147)\n",
      "→ Basket Techs going upward (predicted rating: 0.1396)\n",
      "→ Basket Software in Sweden (predicted rating: 0.1228)\n",
      "→ Basket Sustainable electric equipment (predicted rating: 0.1212)\n",
      "\n",
      "Recommendations for user 1002:\n",
      "→ Basket Growth Rockets (predicted rating: 0.2994)\n",
      "→ Basket Software in Sweden (predicted rating: 0.1955)\n",
      "→ Basket Blockchain and crypto (predicted rating: 0.1800)\n",
      "→ Basket Super software (predicted rating: 0.1541)\n",
      "→ Basket Renewable energy world ALL (predicted rating: 0.1337)\n",
      "\n",
      "Recommendations for user 1003:\n",
      "→ Basket Food world 7 (predicted rating: 0.2932)\n",
      "→ Basket Well traded stocks (predicted rating: 0.2494)\n",
      "→ Basket Healthcare Facilities (predicted rating: 0.1705)\n",
      "→ Basket Healthcare Northern Europe (predicted rating: 0.1208)\n",
      "→ Basket Nordic Construction Companies (predicted rating: 0.0937)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load data\n",
    "train_data = pd.read_csv('y_train.csv')\n",
    "test_data = pd.read_csv('y_test.csv')\n",
    "investments = pd.read_csv('../syntheticDataGenerators/investment/invest_data.csv', sep=';')\n",
    "\n",
    "# Create a basket encoder\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Extract all unique basket names from both datasets\n",
    "all_basket_names = np.union1d(train_data['basket_name'].unique(), \n",
    "                              test_data['basket_name'].unique())\n",
    "\n",
    "# Create and fit the encoder\n",
    "basket_encoder = LabelEncoder()\n",
    "basket_encoder.fit(all_basket_names)\n",
    "\n",
    "# Apply the encoding to get encoded basket values\n",
    "train_data['basket_encoded'] = basket_encoder.transform(train_data['basket_name'])\n",
    "test_data['basket_encoded'] = basket_encoder.transform(test_data['basket_name'])\n",
    "\n",
    "# Get all unique users and baskets (using the encoded values)\n",
    "unique_users = investments['user_id'].unique()\n",
    "unique_baskets = np.union1d(train_data['basket_encoded'].unique(), \n",
    "                           test_data['basket_encoded'].unique())\n",
    "\n",
    "# Process training data\n",
    "# Convert to user-item-rating format\n",
    "train_ratings = []\n",
    "for user in train_data['user_id'].unique():\n",
    "    # Get all baskets this user has invested in\n",
    "    invested_baskets = train_data[train_data['user_id'] == user]['basket_encoded'].values\n",
    "    \n",
    "    # For each basket, add a rating of 1 (user invested)\n",
    "    for basket in invested_baskets:\n",
    "        train_ratings.append({'user_id': user, 'basket_encoded': basket, 'binary_rating': 1})\n",
    "    \n",
    "    # For baskets the user hasn't invested in, add a rating of 0\n",
    "    non_invested = [b for b in unique_baskets if b not in invested_baskets]\n",
    "    for basket in non_invested:\n",
    "        train_ratings.append({'user_id': user, 'basket_encoded': basket, 'binary_rating': 0})\n",
    "\n",
    "train_df = pd.DataFrame(train_ratings)\n",
    "\n",
    "# Process test data similarly\n",
    "test_ratings = []\n",
    "for user in test_data['user_id'].unique():\n",
    "    # Get all baskets this user has invested in\n",
    "    invested_baskets = test_data[test_data['user_id'] == user]['basket_encoded'].values\n",
    "    \n",
    "    # For each basket, add a rating of 1 (user invested)\n",
    "    for basket in invested_baskets:\n",
    "        test_ratings.append({'user_id': user, 'basket_encoded': basket, 'binary_rating': 1})\n",
    "    \n",
    "    # For baskets the user hasn't invested in, add a rating of 0\n",
    "    non_invested = [b for b in unique_baskets if b not in invested_baskets]\n",
    "    for basket in non_invested:\n",
    "        test_ratings.append({'user_id': user, 'basket_encoded': basket, 'binary_rating': 0})\n",
    "\n",
    "test_df = pd.DataFrame(test_ratings)\n",
    "\n",
    "# Create Surprise datasets\n",
    "reader = Reader(rating_scale=(0, 1))\n",
    "\n",
    "trainset = Dataset.load_from_df(\n",
    "    train_df[['user_id', 'basket_encoded', 'binary_rating']], \n",
    "    reader\n",
    ").build_full_trainset()\n",
    "\n",
    "# For the testset, convert to (user, item, rating) tuples\n",
    "testset = [(uid, iid, r) for uid, iid, r in \n",
    "           test_df[['user_id', 'basket_encoded', 'binary_rating']].itertuples(index=False)]\n",
    "\n",
    "#  Grid search for hyperparameter tuning\n",
    "param_grid = {\n",
    "    \"n_epochs\": [10, 20, 40], \n",
    "    \"lr_all\": [0.001, 0.002, 0.005], \n",
    "    \"reg_all\": [0.001, 0.002, 0.004]\n",
    "}\n",
    "\n",
    "# Create a full dataset for grid search\n",
    "full_dataset = Dataset.load_from_df(\n",
    "    pd.concat([train_df, test_df])[['user_id', 'basket_encoded', 'binary_rating']], \n",
    "    reader\n",
    ")\n",
    "\n",
    "# Run grid search\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"mae\"], cv=3, refit=True)\n",
    "gs.fit(full_dataset)\n",
    "\n",
    "# Get best parameters\n",
    "best_params = gs.best_params[\"mae\"]\n",
    "print(f\"Best parameters: {best_params}\")\n",
    "\n",
    "# Initialize SVD with best parameters\n",
    "model_SVD = SVD(\n",
    "    n_epochs=best_params[\"n_epochs\"],\n",
    "    lr_all=best_params[\"lr_all\"],\n",
    "    reg_all=best_params[\"reg_all\"]\n",
    ")\n",
    "\n",
    "# Use default parameters for quick testing\n",
    "# model_SVD = SVD(n_epochs=20, lr_all=0.005, reg_all=0.002)\n",
    "\n",
    "# Fit the model\n",
    "model_SVD.fit(trainset)\n",
    "\n",
    "# Test model\n",
    "predictions = model_SVD.test(testset)\n",
    "\n",
    "# Evaluate with RMSE and MAE\n",
    "print(\"\\nSVD model with binary data:\")\n",
    "print(\"RMSE: Root Mean Squared Error. Lower values mean better accuracy.\")\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(f\"RMSE: {rmse}\")\n",
    "print(\"MAE: Mean Absolute Error. Lower values mean better accuracy.\")\n",
    "mae = accuracy.mae(predictions)\n",
    "print(f\"MAE: {mae}\")\n",
    "\n",
    "# Make recommendation for a specific user\n",
    "user_id = 1001  # Choose a user ID to make recommendations for\n",
    "\n",
    "# Get baskets the user has already invested in\n",
    "already_invested = train_data[train_data['user_id'] == user_id]['basket_encoded'].unique()\n",
    "if len(already_invested) == 0:  # Check if user is in test data\n",
    "    already_invested = test_data[test_data['user_id'] == user_id]['basket_encoded'].unique()\n",
    "\n",
    "# Get baskets the user hasn't invested in yet\n",
    "baskets_to_predict = [b for b in unique_baskets if b not in already_invested]\n",
    "\n",
    "# Predict user's interests for new baskets\n",
    "user_predictions = [model_SVD.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "# Sort by predicted rating (highest first)\n",
    "top_recommendations = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:5]\n",
    "\n",
    "print(f\"\\nTop 5 recommended baskets for user {user_id}:\")\n",
    "for pred in top_recommendations:\n",
    "    # Get original basket name for better readability\n",
    "    basket_name = basket_encoder.inverse_transform([pred.iid])[0]\n",
    "    print(f\"→ Basket {basket_name} (predicted rating: {pred.est:.4f})\")\n",
    "\n",
    "# Function to get recommendations for any user\n",
    "def get_recommendations(user_id, num_recommendations=5):\n",
    "    \"\"\"Get top basket recommendations for a specific user.\"\"\"\n",
    "    # Check if user exists in our data\n",
    "    if user_id not in unique_users:\n",
    "        print(f\"User {user_id} not found in the dataset.\")\n",
    "        return []\n",
    "    \n",
    "    # Get baskets the user has already invested in\n",
    "    already_invested = train_data[train_data['user_id'] == user_id]['basket_encoded'].unique()\n",
    "    if len(already_invested) == 0:  # Check if user is in test data\n",
    "        already_invested = test_data[test_data['user_id'] == user_id]['basket_encoded'].unique()\n",
    "    \n",
    "    # Get baskets the user hasn't invested in yet\n",
    "    baskets_to_predict = [b for b in unique_baskets if b not in already_invested]\n",
    "    \n",
    "    # Predict user's interests for new baskets\n",
    "    user_predictions = [model_SVD.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "    # Sort by predicted rating (highest first)\n",
    "    top_recommendations = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:num_recommendations]\n",
    "    \n",
    "    # Return both encoded id and original name for better usability\n",
    "    return [(pred.iid, basket_encoder.inverse_transform([pred.iid])[0], pred.est) \n",
    "            for pred in top_recommendations]\n",
    "\n",
    "# Example usage of the recommendation function\n",
    "print(\"\\nTesting recommendation function:\")\n",
    "for test_user in list(unique_users)[:3]:  # Get recommendations for first 3 users\n",
    "    recommendations = get_recommendations(test_user)\n",
    "    print(f\"Recommendations for user {test_user}:\")\n",
    "    for basket_id, basket_name, rating in recommendations:\n",
    "        print(f\"→ Basket {basket_name} (predicted rating: {rating:.4f})\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fb4a5b1c-e442-4e9d-ac06-4986dcd95bb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics for Top-K Recommendations:\n",
      "\n",
      "Metrics for k=1:\n",
      "Precision@1: 0.1529\n",
      "Recall@1: 0.1137\n",
      "F1@1: 0.1268\n",
      "Number of users evaluated: 994\n",
      "\n",
      "Metrics for k=2:\n",
      "Precision@2: 0.1127\n",
      "Recall@2: 0.1655\n",
      "F1@2: 0.1303\n",
      "Number of users evaluated: 994\n",
      "\n",
      "Metrics for k=3:\n",
      "Precision@3: 0.0915\n",
      "Recall@3: 0.2017\n",
      "F1@3: 0.1227\n",
      "Number of users evaluated: 994\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store precision, recall, and F1 values\n",
    "precision_at_k = collections.defaultdict(list)\n",
    "recall_at_k = collections.defaultdict(list)\n",
    "f1_at_k = collections.defaultdict(list)\n",
    "\n",
    "# Get all unique test users\n",
    "test_user_ids = test_data['user_id'].unique()\n",
    "\n",
    "# For each user in the test set\n",
    "for user_id in test_user_ids:\n",
    "    # Find baskets this user has invested in from test data (ground truth)\n",
    "    user_positive_test_baskets = set(test_data[test_data['user_id'] == user_id]['basket_encoded'])\n",
    "    \n",
    "    # If no positive test baskets, skip this user\n",
    "    if len(user_positive_test_baskets) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Find baskets the user has already invested in from train data\n",
    "    user_invested_train_baskets = set(train_data[train_data['user_id'] == user_id]['basket_encoded'])\n",
    "    \n",
    "    # Baskets to predict (all baskets minus those already invested in from training)\n",
    "    # Evaluate against ALL possible baskets, including ones they already invested in:\n",
    "    # baskets_to_predict = [b for b in unique_baskets]\n",
    "    \n",
    "    # Exclude baskets they've already invested in from training:\n",
    "    baskets_to_predict = [b for b in unique_baskets if b not in user_invested_train_baskets]\n",
    "    \n",
    "    # Make predictions for all candidate baskets\n",
    "    user_predictions = [model_SVD.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "    sorted_predictions = sorted(user_predictions, key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Calculate precision and recall at different k values\n",
    "    for k in [1, 2, 3]:\n",
    "        # Ensure k doesn't exceed number of predictions\n",
    "        effective_k = min(k, len(sorted_predictions))\n",
    "        \n",
    "        # Skip if no predictions\n",
    "        if effective_k == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get top-k recommended baskets\n",
    "        top_k_recs = [pred.iid for pred in sorted_predictions[:effective_k]]\n",
    "        \n",
    "        # Calculate relevant items among top-k recommendations (positive baskets in test set)\n",
    "        true_positives = len(set(top_k_recs) & user_positive_test_baskets)\n",
    "        \n",
    "        # Precision = relevant recommended / all recommended\n",
    "        precision = true_positives / effective_k\n",
    "        \n",
    "        # Recall = relevant recommended / all relevant\n",
    "        recall = true_positives / len(user_positive_test_baskets)\n",
    "        \n",
    "        # F1 score = 2 * (precision * recall) / (precision + recall)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        precision_at_k[k].append(precision)\n",
    "        recall_at_k[k].append(recall)\n",
    "        f1_at_k[k].append(f1)\n",
    "\n",
    "# Calculate average precision, recall, and F1 for each k\n",
    "print(\"\\nEvaluation Metrics for Top-K Recommendations:\")\n",
    "for k in [1, 2, 3]:\n",
    "    avg_precision = np.mean(precision_at_k[k]) if precision_at_k[k] else 0\n",
    "    avg_recall = np.mean(recall_at_k[k]) if recall_at_k[k] else 0\n",
    "    avg_f1 = np.mean(f1_at_k[k]) if f1_at_k[k] else 0\n",
    "    \n",
    "    print(f\"\\nMetrics for k={k}:\")\n",
    "    print(f\"Precision@{k}: {avg_precision:.4f}\")\n",
    "    print(f\"Recall@{k}: {avg_recall:.4f}\")\n",
    "    print(f\"F1@{k}: {avg_f1:.4f}\")\n",
    "    \n",
    "    print(f\"Number of users evaluated: {len(precision_at_k[k])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2a90a3bf-1480-4327-b3ef-381762015813",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. A more efficient KNN implementation\n",
    "from surprise import KNNWithMeans\n",
    "\n",
    "# 2. Pre-compute similarities and use a smaller neighborhood\n",
    "sim_options = {\n",
    "    'name': 'cosine',\n",
    "    'user_based': True,  # User-based filtering\n",
    "    'min_support': 3     # Minimum number of common items before considering similarity\n",
    "}\n",
    "\n",
    "# 3. Use pre-computed similarities\n",
    "model_KNN = KNNWithMeans(k=10, sim_options=sim_options, verbose=False)\n",
    "\n",
    "# 4. Fit the model (this will now pre-compute similarities)\n",
    "model_KNN.fit(trainset)\n",
    "\n",
    "# 5. For faster prediction on large sets of items, use this approach\n",
    "predictions = []\n",
    "unique_baskets_list = list(unique_baskets)\n",
    "\n",
    "# Process in smaller batches instead of one by one\n",
    "batch_size = 100\n",
    "for i in range(0, len(unique_baskets_list), batch_size):\n",
    "    batch = unique_baskets_list[i:i+batch_size]\n",
    "    batch_predictions = [model_KNN.predict(user_id, basket) for basket in batch]\n",
    "    predictions.extend(batch_predictions)\n",
    "    \n",
    "# 6. Sort predictions afterwards\n",
    "top_recommendations = sorted(predictions, key=lambda x: x.est, reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "abd47adc-d07e-435d-a600-8f7f817237fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation Metrics for Top-K Recommendations:\n",
      "\n",
      "Metrics for k=1:\n",
      "Precision@1: 0.1861\n",
      "Recall@1: 0.1343\n",
      "F1@1: 0.1516\n",
      "Number of users evaluated: 994\n",
      "\n",
      "Metrics for k=2:\n",
      "Precision@2: 0.1459\n",
      "Recall@2: 0.2108\n",
      "F1@2: 0.1675\n",
      "Number of users evaluated: 994\n",
      "\n",
      "Metrics for k=3:\n",
      "Precision@3: 0.1234\n",
      "Recall@3: 0.2681\n",
      "F1@3: 0.1647\n",
      "Number of users evaluated: 994\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store precision, recall, and F1 values\n",
    "precision_at_k = collections.defaultdict(list)\n",
    "recall_at_k = collections.defaultdict(list)\n",
    "f1_at_k = collections.defaultdict(list)\n",
    "\n",
    "# Get all unique test users\n",
    "test_user_ids = test_data['user_id'].unique()\n",
    "\n",
    "# For each user in the test set\n",
    "for user_id in test_user_ids:\n",
    "    # Find baskets this user has invested in from test data (ground truth)\n",
    "    user_positive_test_baskets = set(test_data[test_data['user_id'] == user_id]['basket_encoded'])\n",
    "    \n",
    "    # If no positive test baskets, skip this user\n",
    "    if len(user_positive_test_baskets) == 0:\n",
    "        continue\n",
    "    \n",
    "    # Find baskets the user has already invested in from train data\n",
    "    user_invested_train_baskets = set(train_data[train_data['user_id'] == user_id]['basket_encoded'])\n",
    "    \n",
    "    # Baskets to predict (all baskets minus those already invested in from training)\n",
    "    # To evaluate against ALL possible baskets, including ones they already invested in:\n",
    "    # baskets_to_predict = [b for b in unique_baskets]\n",
    "    \n",
    "    # Exclude baskets they've already invested in from training:\n",
    "    baskets_to_predict = [b for b in unique_baskets if b not in user_invested_train_baskets]\n",
    "    \n",
    "    # Make predictions for all candidate baskets\n",
    "    user_predictions = [model_KNN.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "    sorted_predictions = sorted(user_predictions, key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Calculate precision and recall at different k values\n",
    "    for k in [1, 2, 3]:\n",
    "        # Ensure k doesn't exceed number of predictions\n",
    "        effective_k = min(k, len(sorted_predictions))\n",
    "        \n",
    "        # Skip if no predictions\n",
    "        if effective_k == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get top-k recommended baskets\n",
    "        top_k_recs = [pred.iid for pred in sorted_predictions[:effective_k]]\n",
    "        \n",
    "        # Calculate relevant items among top-k recommendations (positive baskets in test set)\n",
    "        true_positives = len(set(top_k_recs) & user_positive_test_baskets)\n",
    "        \n",
    "        # Precision = relevant recommended / all recommended\n",
    "        precision = true_positives / effective_k\n",
    "        \n",
    "        # Recall = relevant recommended / all relevant\n",
    "        recall = true_positives / len(user_positive_test_baskets)\n",
    "        \n",
    "        # F1 score = 2 * (precision * recall) / (precision + recall)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        precision_at_k[k].append(precision)\n",
    "        recall_at_k[k].append(recall)\n",
    "        f1_at_k[k].append(f1)\n",
    "\n",
    "# Calculate average precision, recall, and F1 for each k\n",
    "print(\"\\nEvaluation Metrics for Top-K Recommendations:\")\n",
    "for k in [1, 2, 3]:\n",
    "    avg_precision = np.mean(precision_at_k[k]) if precision_at_k[k] else 0\n",
    "    avg_recall = np.mean(recall_at_k[k]) if recall_at_k[k] else 0\n",
    "    avg_f1 = np.mean(f1_at_k[k]) if f1_at_k[k] else 0\n",
    "    \n",
    "    print(f\"\\nMetrics for k={k}:\")\n",
    "    print(f\"Precision@{k}: {avg_precision:.4f}\")\n",
    "    print(f\"Recall@{k}: {avg_recall:.4f}\")\n",
    "    print(f\"F1@{k}: {avg_f1:.4f}\")\n",
    "    \n",
    "    print(f\"Number of users evaluated: {len(precision_at_k[k])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5159211-fa55-4b00-9b69-01a0fb12503c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
