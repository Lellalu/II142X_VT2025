{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Load basket data\n",
    "basket_df = pd.read_csv(\"data/company_basket.csv\", sep=\";\")\n",
    "\n",
    "# Load all stock data files\n",
    "sweden_stock_files = glob.glob(\"data/Sweden_*.txt\")\n",
    "new_txt_files = glob.glob(\"data/data-*-*-*.txt\")\n",
    "new_csv_files = glob.glob(\"data/data-*-*-*.csv\")\n",
    "all_files = sweden_stock_files + new_txt_files + new_csv_files\n",
    "\n",
    "# Function to read stock data files\n",
    "def read_file(file_path):\n",
    "    if file_path.endswith('.txt') or file_path.endswith('.csv'):\n",
    "        return pd.read_csv(file_path, sep=\";\")\n",
    "    else:\n",
    "        raise ValueError(f\"Unsupported file extension for {file_path}\")\n",
    "\n",
    "# Load and merge stock data\n",
    "stock_data = pd.concat([read_file(f) for f in all_files])\n",
    "\n",
    "# Ensure all companies have an industry and sector\n",
    "stock_data[\"industry_name\"] = stock_data[\"industry_name\"].fillna(\"Unknown\")\n",
    "stock_data[\"economic_sector_name\"] = stock_data[\"economic_sector_name\"].fillna(\"Unknown\")\n",
    "\n",
    "# --------- One-Hot Encoding Industry and Sector ---------\n",
    "industry_encoded = pd.get_dummies(stock_data[['company_name', 'industry_name']], columns=['industry_name'])\n",
    "sector_encoded = pd.get_dummies(stock_data[['company_name', 'economic_sector_name']], columns=['economic_sector_name'])\n",
    "\n",
    "# Merge one-hot encoded data\n",
    "stock_features = pd.concat([industry_encoded, sector_encoded.drop(\"company_name\", axis=1)], axis=1)\n",
    "\n",
    "# Aggregate at the company level\n",
    "stock_features = stock_features.groupby(\"company_name\").max().astype(int).reset_index()\n",
    "\n",
    "# --------- Market Cap Classification (Size & Risk Level) ---------\n",
    "# Define Market Cap bins\n",
    "mcap_bins = [0, 2e9, 10e9, float(\"inf\")]  # Small, Mid, Large Cap\n",
    "mcap_labels = [\"Small-Cap\", \"Mid-Cap\", \"Large-Cap\"]\n",
    "\n",
    "# Filter Mcap data and classify stocks\n",
    "mcap_data = stock_data[stock_data[\"finparametername\"] == \"Mcap\"].copy()\n",
    "mcap_data[\"size_category\"] = pd.cut(mcap_data[\"finval\"], bins=mcap_bins, labels=mcap_labels)\n",
    "\n",
    "# Assign Risk Level based on Market Cap classification\n",
    "risk_mapping = {\"Small-Cap\": \"High Risk\", \"Mid-Cap\": \"Medium Risk\", \"Large-Cap\": \"Low Risk\"}\n",
    "mcap_data[\"risk_level\"] = mcap_data[\"size_category\"].map(risk_mapping)\n",
    "\n",
    "# One-hot encode size and risk level\n",
    "size_encoded = pd.get_dummies(mcap_data[['company_name', 'size_category']], columns=['size_category'])\n",
    "risk_encoded = pd.get_dummies(mcap_data[['company_name', 'risk_level']], columns=['risk_level'])\n",
    "\n",
    "# Merge size & risk category into stock features\n",
    "stock_features = pd.merge(stock_features, size_encoded, on=\"company_name\", how=\"left\").fillna(0)\n",
    "stock_features = pd.merge(stock_features, risk_encoded, on=\"company_name\", how=\"left\").fillna(0)\n",
    "\n",
    "# --------- Volatility Calculation (Closing Price Std Dev) ---------\n",
    "closing_price_data = stock_data[stock_data[\"finparametername\"] == \"closingPrice\"].copy()\n",
    "\n",
    "# Compute standard deviation of closing price per company\n",
    "volatility = closing_price_data.groupby(\"company_name\")[\"finval\"].std().reset_index()\n",
    "volatility.rename(columns={\"finval\": \"volatility\"}, inplace=True)\n",
    "\n",
    "# Normalize volatility using Min-Max Scaling\n",
    "scaler = MinMaxScaler()\n",
    "volatility[\"scaled_volatility\"] = scaler.fit_transform(volatility[[\"volatility\"]])\n",
    "\n",
    "# Merge volatility into stock features\n",
    "stock_features = pd.merge(stock_features, volatility[[\"company_name\", \"scaled_volatility\"]], on=\"company_name\", how=\"left\").fillna(0)\n",
    "\n",
    "# --------- Create Basket-Level Features ---------\n",
    "def create_basket_features(basket_df, stock_features):\n",
    "    basket_df['company_share'] = basket_df['company_share'] / 100.0\n",
    "    \n",
    "    # Get feature columns\n",
    "    feature_cols = stock_features.columns.drop('company_name')\n",
    "    \n",
    "    # Merge stock features with basket data\n",
    "    merged = pd.merge(basket_df, stock_features, on='company_name')\n",
    "\n",
    "    # Apply weighting based on company share\n",
    "    for col in feature_cols:\n",
    "        merged[col] = merged[col] * merged['company_share']\n",
    "    \n",
    "    # Aggregate at basket level\n",
    "    basket_features = merged.groupby('basket_name')[feature_cols].sum()\n",
    "\n",
    "    return basket_features.reset_index()\n",
    "\n",
    "# Generate basket features\n",
    "basket_features = create_basket_features(basket_df, stock_features)\n",
    "\n",
    "# --------- Compute Cosine Similarity Matrix ---------\n",
    "similarity_matrix = cosine_similarity(basket_features.iloc[:, 1:].values)\n",
    "\n",
    "# Map basket names to indices\n",
    "basket_to_idx = {name: idx for idx, name in enumerate(basket_features['basket_name'])}\n",
    "\n",
    "# --------- Recommendation Function ---------\n",
    "def get_similar_baskets(basket_name, similarity_matrix, n=10):\n",
    "    if basket_name not in basket_features['basket_name'].values:\n",
    "        print(\"\\nAvailable baskets:\")\n",
    "        print(sorted(basket_features['basket_name'].unique()))\n",
    "        raise ValueError(f\"\\nBasket '{basket_name}' not found in the data\")\n",
    "\n",
    "    # Get index for target basket\n",
    "    target_idx = basket_to_idx[basket_name]\n",
    "    \n",
    "    similarity_scores = list(enumerate(similarity_matrix[target_idx]))\n",
    "    similarity_scores = sorted(similarity_scores, key=lambda x: x[1], reverse=True)[1:n+1]\n",
    "\n",
    "    # Get basket names corresponding to top similar indices\n",
    "    similar_baskets = [list(basket_to_idx.keys())[i[0]] for i in similarity_scores]\n",
    "\n",
    "    return similar_baskets\n",
    "\n",
    "# Example: Recommend baskets similar to \"BIG INDEX Global\"\n",
    "recommended_baskets = get_similar_baskets(\"BIG INDEX Global\", similarity_matrix, n=5)\n",
    "print(\"\\nRecommended baskets based on size, risk level, and volatility:\")\n",
    "print(recommended_baskets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# Function to validate basket recommendations\n",
    "def validate_recommendations(input_basket, recommended_baskets, basket_features):\n",
    "    print(f\"\\nValidating Recommendations for Basket: {input_basket}\\n\")\n",
    "\n",
    "    # Get input basket features\n",
    "    input_features = basket_features[basket_features[\"basket_name\"] == input_basket].iloc[:, 1:]\n",
    "\n",
    "    # Print input basket feature values\n",
    "    print(f\"\\nInput Basket: {input_basket}\")\n",
    "    print(input_features)\n",
    "\n",
    "    # Store recommended baskets' features\n",
    "    recommended_data = []\n",
    "    \n",
    "    for basket in recommended_baskets:\n",
    "        if basket in basket_features[\"basket_name\"].values:\n",
    "            basket_feature_values = basket_features[basket_features[\"basket_name\"] == basket].iloc[:, 1:]\n",
    "            avg_mcap = basket_feature_values[\"size_category_Large-Cap\"].values[0] * 10 + \\\n",
    "                       basket_feature_values[\"size_category_Mid-Cap\"].values[0] * 5 + \\\n",
    "                       basket_feature_values[\"size_category_Small-Cap\"].values[0] * 2\n",
    "            avg_risk = basket_feature_values[\"risk_level_High Risk\"].values[0] * 3 + \\\n",
    "                       basket_feature_values[\"risk_level_Medium Risk\"].values[0] * 2 + \\\n",
    "                       basket_feature_values[\"risk_level_Low Risk\"].values[0] * 1\n",
    "            avg_volatility = basket_feature_values[\"scaled_volatility\"].values[0]\n",
    "\n",
    "            recommended_data.append((basket, avg_mcap, avg_risk, avg_volatility))\n",
    "    \n",
    "    # Convert to DataFrame for easier analysis\n",
    "    validation_df = pd.DataFrame(recommended_data, columns=[\"Basket\", \"Avg Mcap Score\", \"Avg Risk Score\", \"Avg Volatility\"])\n",
    "\n",
    "    print(\"\\nRecommended Baskets and Their Financial Features:\\n\")\n",
    "    print(validation_df)\n",
    "\n",
    "    # ----- Visualization -----\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
    "\n",
    "    # Market Cap Comparison\n",
    "    sns.barplot(x=\"Basket\", y=\"Avg Mcap Score\", data=validation_df, ax=axes[0], palette=\"Blues\")\n",
    "    axes[0].set_title(\"Market Cap Score Comparison\")\n",
    "    axes[0].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Risk Level Comparison\n",
    "    sns.barplot(x=\"Basket\", y=\"Avg Risk Score\", data=validation_df, ax=axes[1], palette=\"Oranges\")\n",
    "    axes[1].set_title(\"Risk Level Score Comparison\")\n",
    "    axes[1].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    # Volatility Comparison\n",
    "    sns.barplot(x=\"Basket\", y=\"Avg Volatility\", data=validation_df, ax=axes[2], palette=\"Greens\")\n",
    "    axes[2].set_title(\"Volatility Comparison\")\n",
    "    axes[2].tick_params(axis=\"x\", rotation=45)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Run validation\n",
    "validate_recommendations(\"BIG INDEX Global\", recommended_baskets, basket_features)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
