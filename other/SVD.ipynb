{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from surprise import SVD, Dataset, Reader, KNNBasic\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "import numpy as np\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD model:\n",
      "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
      "RMSE: 0.0966\n",
      "MAE: Mean Absolute Error. Lower values mean better accuracy.\n",
      "MAE:  0.0758\n",
      "FCP:Fraction of Concordant Pairs. Higher values mean better accuracy.\n",
      "FCP:  0.5121\n",
      "\n",
      "Topp 5 rekommenderade baskets för användare 1001:\n",
      "→ High profits with growth (förväntad rating: 0.43)\n",
      "→ German Broadcasting (förväntad rating: 0.41)\n",
      "→ Australian Health 2 (förväntad rating: 0.41)\n",
      "→ Software Australian small comp (förväntad rating: 0.40)\n",
      "→ Techs going upward (förväntad rating: 0.39)\n"
     ]
    }
   ],
   "source": [
    "#USING DEFAULT TRAIN-TEST DATASET DIVISION IN SURPRISE\n",
    "# 1. Data loading\n",
    "investments = pd.read_csv('syntheticDataGenerators/investment/invest_data.csv', sep=';')\n",
    "\n",
    "# 2. Calculate total investment amount for each user\n",
    "user_totals = investments.groupby('user_id')['investment_amount'].sum()\n",
    "\n",
    "# 3. Create a new column for normalized ratings\n",
    "investments['normalized_rating'] = investments.apply(\n",
    "    lambda row: row['investment_amount'] / user_totals[row['user_id']], \n",
    "    axis=1\n",
    ")\n",
    "\n",
    "# 4. Now use these normalized ratings with Surprise\n",
    "reader = Reader(rating_scale=(0, 1))  # Since our ratings are now between 0 and 1\n",
    "data = Dataset.load_from_df(investments[['user_id', 'basket_name', 'normalized_rating']], reader)\n",
    "\n",
    "# 5. Divide data into training och test(20%) dataset\n",
    "trainset, testset = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# 6. Train SVD-model\n",
    "model_SVD = SVD()\n",
    "model_SVD.fit(trainset)\n",
    "\n",
    "# 7. Test model\n",
    "predictions = model_SVD.test(testset)\n",
    "\n",
    "# 8. Evaluate with RMSE, MAE and FCP\n",
    "print(\"SVD model:\")\n",
    "print(\"RMSE: Root Mean Squared Error. Lower values mean better accuracy.\")\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"MAE: Mean Absolute Error. Lower values mean better accuracy.\")\n",
    "mae = accuracy.mae(predictions)\n",
    "print(\"FCP:Fraction of Concordant Pairs. Higher values mean better accuracy.\")\n",
    "fcp = accuracy.fcp(predictions)\n",
    "\n",
    "# 9. Make recommendation to a specific user\n",
    "user_id = 1001\n",
    "all_baskets = investments['basket_name'].unique()\n",
    "already_invested = investments[investments['user_id'] == user_id]['basket_name'].unique()\n",
    "baskets_to_predict = [b for b in all_baskets if b not in already_invested]\n",
    "\n",
    "# 10. Predict user's intresses for new baskets\n",
    "user_predictions = [model_SVD.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "top_recommendations = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:5]\n",
    "\n",
    "print(f\"\\nTopp 5 rekommenderade baskets för användare {user_id}:\")\n",
    "for pred in top_recommendations:\n",
    "    print(f\"→ {pred.iid} (förväntad rating: {pred.est:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVD model:\n",
      "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
      "RMSE: 0.0679\n",
      "MAE: Mean Absolute Error. Lower values mean better accuracy.\n",
      "MAE:  0.0537\n",
      "\n",
      "Topp 5 rekommenderade baskets för användare 1001:\n",
      "→ Cross over well performing (förväntad rating: 0.41)\n",
      "→ Software Americas, small mcap (förväntad rating: 0.37)\n",
      "→ Swedish tech (förväntad rating: 0.34)\n",
      "→ French companies (förväntad rating: 0.33)\n",
      "→ French steel (förväntad rating: 0.33)\n"
     ]
    }
   ],
   "source": [
    "from surprise.model_selection import GridSearchCV\n",
    "\n",
    "#USING MANUAL TRAIN-TEST DATASET DIVISION: 80% user data used for tarining, 20% user used for test\n",
    "# Data loading\n",
    "investments = pd.read_csv('syntheticDataGenerators/investment/invest_data.csv', sep=';')\n",
    "\n",
    "# Calculate total investment amount for each user\n",
    "user_totals = investments.groupby('user_id')['investment_amount'].sum()\n",
    "\n",
    "# Create a new column for normalized ratings\n",
    "investments['normalized_rating'] = investments.apply(\n",
    "    lambda row: row['investment_amount'] / user_totals[row['user_id']], axis=1\n",
    ")\n",
    "\n",
    "# Now use these normalized ratings with Surprise\n",
    "reader = Reader(rating_scale=(0, 1))   # Since our ratings are now between 0 and 1\n",
    "\n",
    "# Get unique list of users\n",
    "unique_users = investments['user_id'].unique()\n",
    "\n",
    "# Sort users\n",
    "sorted_users = np.sort(unique_users)\n",
    "\n",
    "# Calculate the split point (80% of users)\n",
    "split_idx = int(len(sorted_users) * 0.8)\n",
    "\n",
    "# Get training and testing user sets\n",
    "train_users = sorted_users[:split_idx]\n",
    "test_users = sorted_users[split_idx:]\n",
    "\n",
    "# Filter data by user groups\n",
    "train_data = investments[investments['user_id'].isin(train_users)]\n",
    "test_data = investments[investments['user_id'].isin(test_users)]\n",
    "\n",
    "# Now create the Surprise datasets with the normalized ratings\n",
    "trainset = Dataset.load_from_df(\n",
    "    train_data[['user_id', 'basket_name', 'normalized_rating']], \n",
    "    reader\n",
    ").build_full_trainset()\n",
    "\n",
    "# For the testset, we need to convert it to the proper format for testing\n",
    "# (user, item, rating) tuples\n",
    "testset = [(uid, iid, r) for uid, iid, r in \n",
    "           test_data[['user_id', 'basket_name', 'normalized_rating']].itertuples(index=False)]\n",
    "\n",
    "param_grid = {\"n_epochs\": [10, 20, 40, 80], \"lr_all\": [0.0005, 0.001, 0.002, 0.005], \"reg_all\": [0.0005, 0.001, 0.002, 0.004]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=[\"mae\"], cv=3, refit=True)\n",
    "gs.fit(data)\n",
    "\n",
    "model_SVD = SVD()\n",
    "model_SVD.fit(trainset)\n",
    "\n",
    "# Test model\n",
    "predictions = model_SVD.test(testset)\n",
    "\n",
    "# Evaluate with RMSE, MAE and FCP\n",
    "print(\"SVD model:\")\n",
    "print(\"RMSE: Root Mean Squared Error. Lower values mean better accuracy.\")\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"MAE: Mean Absolute Error. Lower values mean better accuracy.\")\n",
    "mae = accuracy.mae(predictions)\n",
    "\n",
    "# Make recommendation to a specific user\n",
    "user_id = 1001\n",
    "all_baskets = investments['basket_name'].unique()\n",
    "already_invested = investments[investments['user_id'] == user_id]['basket_name'].unique()\n",
    "baskets_to_predict = [b for b in all_baskets if b not in already_invested]\n",
    "\n",
    "# Predict user's intresses for new baskets\n",
    "user_predictions = [model_SVD.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "top_recommendations = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:5]\n",
    "\n",
    "print(f\"\\nTopp 5 rekommenderade baskets för användare {user_id}:\")\n",
    "for pred in top_recommendations:\n",
    "    print(f\"→ {pred.iid} (förväntad rating: {pred.est:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@2: 0.1734\n",
      "Recall@2: 0.0630\n",
      "F1@2: 0.0916\n",
      "Precision@5: 0.1487\n",
      "Recall@5: 0.1408\n",
      "F1@5: 0.1426\n",
      "Precision@8: 0.1149\n",
      "Recall@8: 0.1737\n",
      "F1@8: 0.1364\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store precision and recall values\n",
    "precision_at_k = collections.defaultdict(list)\n",
    "recall_at_k = collections.defaultdict(list)\n",
    "f1_at_k = collections.defaultdict(list)\n",
    "\n",
    "# Get all unique test users\n",
    "test_user_ids = np.unique([uid for uid, _, _ in testset])\n",
    "\n",
    "# Get all unique baskets\n",
    "all_baskets = investments['basket_name'].unique()\n",
    "\n",
    "# For each user in the test set\n",
    "for user_id in test_user_ids:    \n",
    "    # Find baskets this user has interacted with in test data (ground truth)\n",
    "    user_test_data = test_data[test_data['user_id'] == user_id]\n",
    "    user_test_baskets = set(user_test_data['basket_name'].unique())\n",
    "    \n",
    "    # If no test baskets, skip this user\n",
    "    if len(user_test_baskets) == 0:\n",
    "        continue\n",
    "        \n",
    "    # Find baskets to predict for\n",
    "    baskets_to_predict = [b for b in all_baskets]\n",
    "    \n",
    "    # Make predictions for all baskets\n",
    "    user_predictions = [model_SVD.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "    sorted_predictions = sorted(user_predictions, key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Calculate precision and recall at different k values\n",
    "    for k in [2, 5, 8]:\n",
    "        # Get top-k recommended baskets\n",
    "        top_k_recs = [pred.iid for pred in sorted_predictions[:k]]\n",
    "        \n",
    "        # Calculate relevant items among top-k recommendations (items that appear in test set)\n",
    "        true_positives = len(set(top_k_recs) & user_test_baskets)\n",
    "        \n",
    "        # Precision = relevant recommended / all recommended\n",
    "        precision = true_positives / k\n",
    "        \n",
    "        # Recall = relevant recommended / all relevant\n",
    "        recall = true_positives / len(user_test_baskets) \n",
    "\n",
    "        # F1 score = 2 * (precision * recall) / (precision + recall)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        precision_at_k[k].append(precision)\n",
    "        recall_at_k[k].append(recall)\n",
    "        f1_at_k[k].append(f1)\n",
    "\n",
    "# Calculate average precision and recall\n",
    "for k in [2, 5, 8]:\n",
    "    avg_precision = np.mean(precision_at_k[k]) if precision_at_k[k] else 0\n",
    "    avg_recall = np.mean(recall_at_k[k]) if recall_at_k[k] else 0\n",
    "    avg_f1 = np.mean(f1_at_k[k]) if f1_at_k[k] else 0\n",
    "    \n",
    "    print(f\"Precision@{k}: {avg_precision:.4f}\")\n",
    "    print(f\"Recall@{k}: {avg_recall:.4f}\")\n",
    "    print(f\"F1@{k}: {avg_f1:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing the msd similarity matrix...\n",
      "Done computing similarity matrix.\n",
      "KNN model:\n",
      "RMSE: Root Mean Squared Error. Lower values mean better accuracy.\n",
      "RMSE: 0.0755\n",
      "MAE: Mean Absolute Error. Lower values mean better accuracy.\n",
      "MAE:  0.0602\n",
      "FCP:Fraction of Concordant Pairs. Higher values mean better accuracy.\n",
      "FCP:  0.0000\n",
      "\n",
      "Topp 5 rekommenderade baskets för användare 1001:\n",
      "→ MooseBit underdog (förväntad rating: 0.30)\n",
      "→ Technology stars of value (förväntad rating: 0.28)\n",
      "→ Well traded with profit margin (förväntad rating: 0.28)\n",
      "→ Great World software (förväntad rating: 0.25)\n",
      "→ Well performed companies (förväntad rating: 0.25)\n"
     ]
    }
   ],
   "source": [
    "# 6. Train KNN-model\n",
    "model_KNN = KNNBasic(k=10)\n",
    "model_KNN.fit(trainset)\n",
    "\n",
    "# 7. Test model\n",
    "predictions = model_KNN.test(testset)\n",
    "\n",
    "# 8. Evaluate with RMSE, MAE and FCP\n",
    "print(\"KNN model:\")\n",
    "print(\"RMSE: Root Mean Squared Error. Lower values mean better accuracy.\")\n",
    "rmse = accuracy.rmse(predictions)\n",
    "print(\"MAE: Mean Absolute Error. Lower values mean better accuracy.\")\n",
    "mae = accuracy.mae(predictions)\n",
    "print(\"FCP:Fraction of Concordant Pairs. Higher values mean better accuracy.\")\n",
    "fcp = accuracy.fcp(predictions)\n",
    "\n",
    "# 9. Make recommendation to a specific user\n",
    "user_id = 1001\n",
    "all_baskets = investments['basket_name'].unique()\n",
    "already_invested = investments[investments['user_id'] == user_id]['basket_name'].unique()\n",
    "baskets_to_predict = [b for b in all_baskets if b not in already_invested]\n",
    "\n",
    "# 10. Predict user's intresses for new baskets\n",
    "user_predictions = [model_KNN.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "top_recommendations = sorted(user_predictions, key=lambda x: x.est, reverse=True)[:5]\n",
    "\n",
    "print(f\"\\nTopp 5 rekommenderade baskets för användare {user_id}:\")\n",
    "for pred in top_recommendations:\n",
    "    print(f\"→ {pred.iid} (förväntad rating: {pred.est:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Precision@1: 0.1500\n",
      "Recall@1: 0.0283\n",
      "F1@1: 0.0471\n",
      "Precision@2: 0.1050\n",
      "Recall@2: 0.0412\n",
      "F1@2: 0.0582\n",
      "Precision@3: 0.1983\n",
      "Recall@3: 0.1165\n",
      "F1@3: 0.1448\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to store precision and recall values\n",
    "precision_at_k = collections.defaultdict(list)\n",
    "recall_at_k = collections.defaultdict(list)\n",
    "f1_at_k = collections.defaultdict(list)\n",
    "\n",
    "# Get all unique test users\n",
    "test_user_ids = np.unique([uid for uid, _, _ in testset])\n",
    "\n",
    "# Get all unique baskets\n",
    "all_baskets = investments['basket_name'].unique()\n",
    "\n",
    "# For each user in the test set\n",
    "for user_id in test_user_ids:    \n",
    "    # Find baskets this user has interacted with in test data (ground truth)\n",
    "    user_test_data = test_data[test_data['user_id'] == user_id]\n",
    "    user_test_baskets = set(user_test_data['basket_name'].unique())\n",
    "    \n",
    "    # If no test baskets, skip this user\n",
    "    if len(user_test_baskets) == 0:\n",
    "        continue\n",
    "        \n",
    "    # Find baskets to predict for\n",
    "    baskets_to_predict = [b for b in all_baskets]\n",
    "    \n",
    "    # Make predictions for all baskets\n",
    "    user_predictions = [model_KNN.predict(user_id, basket) for basket in baskets_to_predict]\n",
    "    sorted_predictions = sorted(user_predictions, key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Calculate precision and recall at different k values\n",
    "    for k in [1, 2, 3]:\n",
    "        # Get top-k recommended baskets\n",
    "        top_k_recs = [pred.iid for pred in sorted_predictions[:k]]\n",
    "        \n",
    "        # Calculate relevant items among top-k recommendations (items that appear in test set)\n",
    "        true_positives = len(set(top_k_recs) & user_test_baskets)\n",
    "        \n",
    "        # Precision = relevant recommended / all recommended\n",
    "        precision = true_positives / k\n",
    "        \n",
    "        # Recall = relevant recommended / all relevant\n",
    "        recall = true_positives / len(user_test_baskets) \n",
    "\n",
    "        # F1 score = 2 * (precision * recall) / (precision + recall)\n",
    "        f1 = 2 * (precision * recall) / (precision + recall) if (precision + recall) > 0 else 0\n",
    "        \n",
    "        precision_at_k[k].append(precision)\n",
    "        recall_at_k[k].append(recall)\n",
    "        f1_at_k[k].append(f1)\n",
    "\n",
    "# Calculate average precision and recall\n",
    "for k in [1, 2, 3]:\n",
    "    avg_precision = np.mean(precision_at_k[k]) if precision_at_k[k] else 0\n",
    "    avg_recall = np.mean(recall_at_k[k]) if recall_at_k[k] else 0\n",
    "    avg_f1 = np.mean(f1_at_k[k]) if f1_at_k[k] else 0\n",
    "    \n",
    "    print(f\"Precision@{k}: {avg_precision:.4f}\")\n",
    "    print(f\"Recall@{k}: {avg_recall:.4f}\")\n",
    "    print(f\"F1@{k}: {avg_f1:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
