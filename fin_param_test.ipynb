{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fb0a57e4-c022-4ee0-bfe1-ac13c2558ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import itertools\n",
    "from pathlib import Path\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fa869f6-89c2-4df2-b2de-3e92d0bba711",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading all data into all_event_data\n",
    "\n",
    "root_path = Path('data/')\n",
    "company_basket_file = root_path / 'company_basket.csv'\n",
    "\n",
    "# Load basket data\n",
    "basket_df = pd.read_csv(company_basket_file, sep=\";\")\n",
    "\n",
    "all_event_data = pd.DataFrame()\n",
    "all_txt_files = list(root_path.rglob('Sweden*.txt'))\n",
    "all_csv_file = list(root_path.rglob('data*.csv'))\n",
    "for event_file in tqdm.tqdm(all_txt_files, desc=\"Iterating all txt files\"):\n",
    "    current_df = pd.read_csv(event_file, sep=\";\")\n",
    "    all_event_data = pd.concat([all_event_data, current_df], ignore_index=True)\n",
    "\n",
    "for event_file in tqdm.tqdm(all_csv_file, desc=\"Iterating all csv files\"):\n",
    "    current_df = pd.read_csv(event_file, sep=\",\")\n",
    "    all_event_data = pd.concat([all_event_data, current_df], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6b25837c-f1fd-4e95-901a-0ec5dcdf52a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Iterating all txt files: 100%|█████████████████████████████████████████████| 10/10 [00:04<00:00,  2.24it/s]\n",
      "Iterating all csv files: 100%|█████████████████████████████████████████████| 11/11 [00:10<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "# Generate one hot encoding for each company based on industry_name and economic_sector_name\n",
    "\n",
    "# Drop duplicates when ['country_name', 'industry_name', 'economic_sector_name', 'company_name'] are the same\n",
    "company_dedup_columns = ['country_name', 'industry_name', 'economic_sector_name', 'company_name']\n",
    "company_overview_data = all_event_data.drop_duplicates(subset=company_dedup_columns)\n",
    "company_overview_data = company_overview_data[company_dedup_columns]\n",
    "\n",
    "# --------- One-Hot Encoding Industry and Sector ---------\n",
    "industry_encoded = pd.get_dummies(company_overview_data[['company_name', 'industry_name']], columns=['industry_name'], dtype=int)\n",
    "sector_encoded = pd.get_dummies(company_overview_data[['company_name', 'economic_sector_name']], columns=['economic_sector_name'], dtype=int)\n",
    "\n",
    "# Merge one-hot encoded data\n",
    "stock_features = pd.concat([industry_encoded, sector_encoded.drop(\"company_name\", axis=1)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "241f673f-f3f2-49f0-a062-a8a873c4e7ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country_name</th>\n",
       "      <th>industry_name</th>\n",
       "      <th>economic_sector_name</th>\n",
       "      <th>company_name</th>\n",
       "      <th>finparametername</th>\n",
       "      <th>endtime</th>\n",
       "      <th>finval</th>\n",
       "      <th>Size Category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11217504</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>Specialty Chemicals</td>\n",
       "      <td>Basic Materials</td>\n",
       "      <td>CSW Industrials Inc</td>\n",
       "      <td>Mcap</td>\n",
       "      <td>2024-08-07 00:00:00</td>\n",
       "      <td>4.755978e+09</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11218628</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>Airlines</td>\n",
       "      <td>Industrials</td>\n",
       "      <td>Hawaiian Holdings Inc</td>\n",
       "      <td>Mcap</td>\n",
       "      <td>2024-08-07 00:00:00</td>\n",
       "      <td>6.423208e+08</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289148</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>Electric Utilities</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Genesis Energy Ltd</td>\n",
       "      <td>Mcap</td>\n",
       "      <td>2024-08-07 00:00:00</td>\n",
       "      <td>2.630302e+09</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11239094</th>\n",
       "      <td>United States of America</td>\n",
       "      <td>Leisure &amp; Recreation</td>\n",
       "      <td>Consumer Cyclicals</td>\n",
       "      <td>Travelzoo</td>\n",
       "      <td>Mcap</td>\n",
       "      <td>2024-08-07 00:00:00</td>\n",
       "      <td>2.637225e+08</td>\n",
       "      <td>Small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11289245</th>\n",
       "      <td>Canada</td>\n",
       "      <td>Electric Utilities</td>\n",
       "      <td>Utilities</td>\n",
       "      <td>Innergex Renewable Energy Inc</td>\n",
       "      <td>Mcap</td>\n",
       "      <td>2024-08-07 00:00:00</td>\n",
       "      <td>2.098220e+09</td>\n",
       "      <td>Medium</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      country_name         industry_name economic_sector_name  \\\n",
       "11217504  United States of America   Specialty Chemicals      Basic Materials   \n",
       "11218628  United States of America              Airlines          Industrials   \n",
       "11289148               New Zealand    Electric Utilities            Utilities   \n",
       "11239094  United States of America  Leisure & Recreation   Consumer Cyclicals   \n",
       "11289245                    Canada    Electric Utilities            Utilities   \n",
       "\n",
       "                           company_name finparametername              endtime  \\\n",
       "11217504            CSW Industrials Inc             Mcap  2024-08-07 00:00:00   \n",
       "11218628          Hawaiian Holdings Inc             Mcap  2024-08-07 00:00:00   \n",
       "11289148             Genesis Energy Ltd             Mcap  2024-08-07 00:00:00   \n",
       "11239094                      Travelzoo             Mcap  2024-08-07 00:00:00   \n",
       "11289245  Innergex Renewable Energy Inc             Mcap  2024-08-07 00:00:00   \n",
       "\n",
       "                finval Size Category  \n",
       "11217504  4.755978e+09        Medium  \n",
       "11218628  6.423208e+08         Small  \n",
       "11289148  2.630302e+09        Medium  \n",
       "11239094  2.637225e+08         Small  \n",
       "11289245  2.098220e+09        Medium  "
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Classify companies based on their latest Mcap\n",
    "\n",
    "# Only keep rows where ['finparametername'] == 'Mcap'\n",
    "mcap_df = all_event_data[all_event_data['finparametername'] == 'Mcap'].copy()\n",
    "\n",
    "# Sort endtime and only keep the latest (drop_duplicates only keep the first one)\n",
    "latest_mcap_df = (mcap_df\n",
    "    .sort_values('endtime', ascending=False)\n",
    "    .drop_duplicates(subset=['country_name', 'industry_name', 'economic_sector_name', 'company_name'])\n",
    ")\n",
    "\n",
    "# Define Market Cap bins\n",
    "mcap_bins = [0, 2e9, 10e9, float(\"inf\")]  # Small, Mid, Large Cap\n",
    "mcap_labels = [\"Small\", \"Medium\", \"Large\"]\n",
    "\n",
    "latest_mcap_df[\"Size Category\"] = pd.cut(latest_mcap_df[\"finval\"], bins=mcap_bins, labels=mcap_labels)\n",
    "latest_mcap_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "beee209b-fec6-4e76-a171-40a448bf7c27",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2673/2673 [00:01<00:00, 1712.00it/s]\n"
     ]
    }
   ],
   "source": [
    "# -----Volatility Classification 1 (high, medium, low):  by Industry-Relative Classification-------\n",
    "closing_price_df = all_event_data[all_event_data['finparametername'] == 'closingPrice'].copy()\n",
    "\n",
    "closing_price_df = closing_price_df.sort_values([\n",
    "    'country_name', 'industry_name', 'economic_sector_name', 'company_name', 'endtime'\n",
    "])\n",
    "\n",
    "# Create a list to store results\n",
    "volatility_results = []\n",
    "\n",
    "# Group by all company identifier fields\n",
    "company_groups = closing_price_df.groupby([\n",
    "    'country_name', 'industry_name', 'economic_sector_name', 'company_name'\n",
    "])\n",
    "\n",
    "for company_key, company_data in tqdm.tqdm(company_groups):\n",
    "    country, industry, sector, company = company_key\n",
    "    \n",
    "    # Convert to time series and calculate returns\n",
    "    prices = company_data.set_index('endtime')['finval']\n",
    "    returns = prices.pct_change().dropna()\n",
    "    \n",
    "    # Calculate annualized volatility (assuming daily data)\n",
    "    daily_vol = returns.std()\n",
    "    annualized_vol = daily_vol * np.sqrt(252)\n",
    "    \n",
    "    # Store result\n",
    "    volatility_results.append({\n",
    "        'country_name': country,\n",
    "        'industry_name': industry,\n",
    "        'economic_sector_name': sector,\n",
    "        'company_name': company,\n",
    "        'price_volatility': annualized_vol\n",
    "    })\n",
    "\n",
    "# Create result dataframe\n",
    "volatility_df = pd.DataFrame(volatility_results)\n",
    "\n",
    "industry_groups = volatility_df.groupby('industry_name')\n",
    "\n",
    "volatility_df['volatility_category'] = 'Medium'\n",
    "\n",
    "for industry, group in industry_groups:\n",
    "    low_threshold = group['price_volatility'].quantile(0.33)\n",
    "    high_threshold = group['price_volatility'].quantile(0.67)\n",
    "    \n",
    "    # Apply industry-specific thresholds\n",
    "    industry_mask = volatility_df['industry_name'] == industry\n",
    "    volatility_df.loc[industry_mask & (volatility_df['price_volatility'] <= low_threshold), 'volatility_category'] = 'Low'\n",
    "    volatility_df.loc[industry_mask & (volatility_df['price_volatility'] >= high_threshold), 'volatility_category'] = 'High'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6919b965-d363-43e0-ba11-895ad7b89d76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "volatility_category\n",
       "High      903\n",
       "Low       894\n",
       "Medium    876\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volatility_df.head()\n",
    "volatility_df[\"volatility_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "ca7f1eae-e72c-4c4b-a239-a308ff56db2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████| 2673/2673 [00:01<00:00, 1455.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# -----Volatility Classification 2 (high, medium, low):  by Fixed Thresholds Based on Financial Industry Standards-------\n",
    "\n",
    "closing_price_df = all_event_data[all_event_data['finparametername'] == 'closingPrice'].copy()\n",
    "\n",
    "closing_price_df = closing_price_df.sort_values([\n",
    "    'country_name', 'industry_name', 'economic_sector_name', 'company_name', 'endtime'\n",
    "])\n",
    "\n",
    "# Create a list to store results\n",
    "volatility_results = []\n",
    "\n",
    "# Group by all company identifier fields\n",
    "company_groups = closing_price_df.groupby([\n",
    "    'country_name', 'industry_name', 'economic_sector_name', 'company_name'\n",
    "])\n",
    "\n",
    "for company_key, company_data in tqdm.tqdm(company_groups):\n",
    "    country, industry, sector, company = company_key\n",
    "    \n",
    "    # Convert to time series and calculate returns\n",
    "    prices = company_data.set_index('endtime')['finval']\n",
    "    returns = prices.pct_change().dropna()\n",
    "    \n",
    "    # Calculate annualized volatility (assuming daily data)\n",
    "    daily_vol = returns.std()\n",
    "    annualized_vol = daily_vol * np.sqrt(252)\n",
    "    \n",
    "    # Store result\n",
    "    volatility_results.append({\n",
    "        'country_name': country,\n",
    "        'industry_name': industry,\n",
    "        'economic_sector_name': sector,\n",
    "        'company_name': company,\n",
    "        'price_volatility': annualized_vol\n",
    "    })\n",
    "\n",
    "# Create result dataframe\n",
    "volatility_df = pd.DataFrame(volatility_results)\n",
    "\n",
    "def classify_stock_volatility(volatility_df):\n",
    "    # First cap extreme values (e.g., above 99th percentile)\n",
    "    cap_value = volatility_df['price_volatility'].quantile(0.99)\n",
    "    volatility_df['price_volatility_capped'] = volatility_df['price_volatility'].clip(upper=cap_value)\n",
    "    \n",
    "    # Apply standard classifications to capped values\n",
    "    volatility_df['volatility_category'] = 'Medium'\n",
    "    volatility_df.loc[volatility_df['price_volatility_capped'] < 0.15, 'volatility_category'] = 'Low'\n",
    "    volatility_df.loc[volatility_df['price_volatility_capped'] > 0.30, 'volatility_category'] = 'High'\n",
    "    \n",
    "    return volatility_df\n",
    "\n",
    "volatility_df_2 = classify_stock_volatility(volatility_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "034de603-a1c2-45cd-a49f-b6d9bafbafea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "volatility_category\n",
       "High      1985\n",
       "Medium     650\n",
       "Low         38\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "volatility_df_2[\"volatility_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12db32f3-7311-49e5-9b7a-bc5d138327a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
