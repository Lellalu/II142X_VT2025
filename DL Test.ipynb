{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cb3228b3-0083-48fe-b21c-7fad118139c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "26c53775-fc7f-4133-8ee4-20e7612fcf0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your data\n",
    "investments = pd.read_csv(\"syntheticDataGenerators/investment/invest_data.csv\", sep=';')\n",
    "\n",
    "# Normalize ratings between 0 and 1 per user\n",
    "user_totals = investments.groupby('user_id')['investment_amount'].sum()\n",
    "investments['rating'] = investments.apply(lambda row: row['investment_amount'] / user_totals[row['user_id']], axis=1)\n",
    "\n",
    "# Encode user and basket IDs to integers\n",
    "user2idx = {user_id: idx for idx, user_id in enumerate(investments['user_id'].unique())}\n",
    "basket2idx = {basket: idx for idx, basket in enumerate(investments['basket_name'].unique())}\n",
    "\n",
    "investments['user_idx'] = investments['user_id'].map(user2idx)\n",
    "investments['basket_idx'] = investments['basket_name'].map(basket2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "033bf36f-9fbb-45f8-966c-e8c4027d6bb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecommenderNet(nn.Module):\n",
    "    def __init__(self, num_users, num_items, embedding_size=50):\n",
    "        super().__init__()\n",
    "        self.user_embedding = nn.Embedding(num_users, embedding_size)\n",
    "        self.item_embedding = nn.Embedding(num_items, embedding_size)\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(embedding_size * 2, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, user_ids, item_ids):\n",
    "        user_vecs = self.user_embedding(user_ids)\n",
    "        item_vecs = self.item_embedding(item_ids)\n",
    "        combined = torch.cat([user_vecs, item_vecs], dim=1)\n",
    "        return self.fc(combined).squeeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa057ab3-e327-4615-975b-0eb1f8aa73b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 0.1315, Val Loss = 0.0732\n",
      "Epoch 2: Train Loss = 0.0691, Val Loss = 0.0376\n",
      "Epoch 3: Train Loss = 0.0334, Val Loss = 0.0203\n",
      "Epoch 4: Train Loss = 0.0173, Val Loss = 0.0140\n",
      "Epoch 5: Train Loss = 0.0125, Val Loss = 0.0129\n",
      "Epoch 6: Train Loss = 0.0125, Val Loss = 0.0136\n",
      "Epoch 7: Train Loss = 0.0140, Val Loss = 0.0145\n",
      "Epoch 8: Train Loss = 0.0155, Val Loss = 0.0152\n",
      "Epoch 9: Train Loss = 0.0163, Val Loss = 0.0154\n",
      "Epoch 10: Train Loss = 0.0164, Val Loss = 0.0151\n"
     ]
    }
   ],
   "source": [
    "# Prepare data\n",
    "X = investments[['user_idx', 'basket_idx']].values\n",
    "y = investments['rating'].values.astype(np.float32)\n",
    "\n",
    "# Create user and basket index mappings\n",
    "user2idx = {user: idx for idx, user in enumerate(investments['user_id'].unique())}\n",
    "basket2idx = {basket: idx for idx, basket in enumerate(investments['basket_name'].unique())}\n",
    "\n",
    "# Add index columns to your dataframe\n",
    "investments['user_idx'] = investments['user_id'].map(user2idx)\n",
    "investments['basket_idx'] = investments['basket_name'].map(basket2idx)\n",
    "\n",
    "# Get unique list of users and sort them\n",
    "unique_users = investments['user_id'].unique()\n",
    "sorted_users = np.sort(unique_users)\n",
    "\n",
    "# Calculate the split point (80% of users)\n",
    "split_idx = int(len(sorted_users) * 0.8)\n",
    "\n",
    "# Split users into train and test sets\n",
    "train_users_ids = sorted_users[:split_idx]\n",
    "test_users_ids = sorted_users[split_idx:]\n",
    "\n",
    "# Filter data by user groups\n",
    "train_data = investments[investments['user_id'].isin(train_users_ids)]\n",
    "test_data = investments[investments['user_id'].isin(test_users_ids)]\n",
    "\n",
    "# Prepare features and targets for PyTorch\n",
    "X_train = train_data[['user_idx', 'basket_idx']].values\n",
    "y_train = train_data['rating'].values.astype(np.float32)\n",
    "\n",
    "X_test = test_data[['user_idx', 'basket_idx']].values\n",
    "y_test = test_data['rating'].values.astype(np.float32)\n",
    "\n",
    "# Convert to tensors\n",
    "train_users = torch.tensor(X_train[:, 0])\n",
    "train_items = torch.tensor(X_train[:, 1])\n",
    "train_ratings = torch.tensor(y_train)\n",
    "\n",
    "test_users = torch.tensor(X_test[:, 0])\n",
    "test_items = torch.tensor(X_test[:, 1])\n",
    "test_ratings = torch.tensor(y_test)\n",
    "\n",
    "# Model\n",
    "model = RecommenderNet(num_users=len(user2idx), num_items=len(basket2idx))\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Training loop\n",
    "epochs = 10\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    outputs = model(train_users, train_items)\n",
    "    loss = criterion(outputs, train_ratings)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        val_preds = model(test_users, test_items)\n",
    "        val_loss = criterion(val_preds, test_ratings)\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {loss.item():.4f}, Val Loss = {val_loss.item():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94037500-011c-4ce6-a211-1badaa557dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend_for_users(user_ids, top_n=5):\n",
    "    model.eval()\n",
    "    all_baskets = list(basket2idx.keys())\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        user_idx = user2idx[user_id]\n",
    "        \n",
    "        already_invested = investments[investments['user_id'] == user_id]['basket_name'].unique()\n",
    "        unseen_baskets = [b for b in all_baskets if b not in already_invested]\n",
    "        basket_indices = torch.tensor([basket2idx[b] for b in unseen_baskets])\n",
    "        user_tensor = torch.tensor([user_idx] * len(basket_indices))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            preds = model(user_tensor, basket_indices)\n",
    "        \n",
    "        top_indices = torch.topk(preds, top_n).indices\n",
    "        top_baskets = [(unseen_baskets[i], preds[i].item()) for i in top_indices]\n",
    "\n",
    "        print(f\"\\nðŸ” Top-{top_n} Recommendations for User {user_id}:\")\n",
    "        for basket, score in top_baskets:\n",
    "            print(f\"â†’ {basket} (score: {score:.2f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "76127221-9feb-46dc-bb07-f6c1d38302a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ” Top-5 Recommendations for User 1001:\n",
      "â†’ Danish contracts (score: 0.22)\n",
      "â†’ European fishing (score: 0.22)\n",
      "â†’ Nordic healthcare Facilities (score: 0.21)\n",
      "â†’ Pers 14 (score: 0.21)\n",
      "â†’ Great World software (score: 0.19)\n",
      "\n",
      "ðŸ” Top-5 Recommendations for User 1002:\n",
      "â†’ Danish contracts (score: 0.38)\n",
      "â†’ Great World software (score: 0.36)\n",
      "â†’ Aussi Fin extra (score: 0.33)\n",
      "â†’ Consumer loans (score: 0.32)\n",
      "â†’ Healthcare southern EuropÃ© (score: 0.31)\n",
      "\n",
      "ðŸ” Top-5 Recommendations for User 1003:\n",
      "â†’ Danish contracts (score: 0.37)\n",
      "â†’ Great World software (score: 0.34)\n",
      "â†’ Nordic healthcare Facilities (score: 0.31)\n",
      "â†’ Nordic Construction Companies (score: 0.30)\n",
      "â†’ Aussi Fin extra (score: 0.29)\n",
      "\n",
      "ðŸ” Top-5 Recommendations for User 1004:\n",
      "â†’ Danish contracts (score: 0.32)\n",
      "â†’ Aussi Fin extra (score: 0.29)\n",
      "â†’ Why? Dont get it (score: 0.25)\n",
      "â†’ Healtcare Global valuers (score: 0.23)\n",
      "â†’ Nordic healthcare Facilities (score: 0.19)\n",
      "\n",
      "ðŸ” Top-5 Recommendations for User 1005:\n",
      "â†’ Danish contracts (score: 0.29)\n",
      "â†’ Aussi Fin extra (score: 0.21)\n",
      "â†’ European fishing (score: 0.19)\n",
      "â†’ Great World software (score: 0.19)\n",
      "â†’ Restaurants  Bars (score: 0.18)\n"
     ]
    }
   ],
   "source": [
    "random_user_ids = np.random.choice(list(user2idx.keys()), size=10, replace=False)\n",
    "recommend_for_users([1001, 1002, 1003, 1004, 1005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65b6060e-fc4a-4ef8-be20-5f11b9b6cf9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----- EVALUATION RESULTS -----\n",
      "\n",
      "Metrics at k=2:\n",
      "Precision@2: 0.0125\n",
      "Recall@2: 0.0048\n",
      "F1@2: 0.0068\n",
      "\n",
      "Metrics at k=5:\n",
      "Precision@5: 0.0150\n",
      "Recall@5: 0.0152\n",
      "F1@5: 0.0149\n",
      "\n",
      "Metrics at k=10:\n",
      "Precision@10: 0.0105\n",
      "Recall@10: 0.0203\n",
      "F1@10: 0.0136\n"
     ]
    }
   ],
   "source": [
    "def evaluate_recommendations(user_ids=None, top_n_values=[2, 5, 10]):\n",
    "    \"\"\"\n",
    "    Evaluate the model using precision, recall, and F1 score\n",
    "    for multiple values of top_n recommendations\n",
    "    \"\"\"\n",
    "    model.eval()\n",
    "    all_baskets = list(basket2idx.keys())\n",
    "    \n",
    "    # Use all test users if no specific users are provided\n",
    "    if user_ids is None:\n",
    "        user_ids = test_data['user_id'].unique()\n",
    "    \n",
    "    # Dictionaries to store metrics\n",
    "    precision_at_k = collections.defaultdict(list)\n",
    "    recall_at_k = collections.defaultdict(list)\n",
    "    f1_at_k = collections.defaultdict(list)\n",
    "    \n",
    "    for user_id in user_ids:\n",
    "        # Skip if user is not in test set\n",
    "        if user_id not in test_data['user_id'].unique():\n",
    "            continue\n",
    "            \n",
    "        # Get user index\n",
    "        user_idx = user2idx[user_id]\n",
    "        \n",
    "        # Get baskets from training set (to exclude)\n",
    "        if user_id in train_data['user_id'].unique():\n",
    "            train_baskets = train_data[train_data['user_id'] == user_id]['basket_name'].unique()\n",
    "        else:\n",
    "            train_baskets = []\n",
    "            \n",
    "        # Get ground truth baskets from test set\n",
    "        test_baskets = test_data[test_data['user_id'] == user_id]['basket_name'].unique()\n",
    "        \n",
    "        # Skip if no test baskets\n",
    "        if len(test_baskets) == 0:\n",
    "            continue\n",
    "            \n",
    "        # Get unseen baskets (all baskets minus training baskets)\n",
    "        basket_indices = torch.tensor([basket2idx[b]for b in all_baskets])\n",
    "        user_tensor = torch.tensor([user_idx] * len(basket_indices))\n",
    "        \n",
    "        # Get predictions\n",
    "        with torch.no_grad():\n",
    "            preds = model(user_tensor, basket_indices)\n",
    "        \n",
    "        # Evaluate for different k values\n",
    "        for k in top_n_values:\n",
    "                \n",
    "            # Get top-k recommendations\n",
    "            top_indices = torch.topk(preds, k).indices.numpy()\n",
    "            recommended_baskets = [all_baskets[i] for i in top_indices]\n",
    "            \n",
    "            # Calculate true positives (recommendations that are in test set)\n",
    "            true_positives = len(set(recommended_baskets) & set(test_baskets))\n",
    "            \n",
    "            # Calculate metrics\n",
    "            precision = true_positives / k\n",
    "            recall = true_positives / len(test_baskets)\n",
    "            f1 = 2 * precision * recall / (precision + recall) if precision + recall > 0 else 0\n",
    "            \n",
    "            # Store metrics\n",
    "            precision_at_k[k].append(precision)\n",
    "            recall_at_k[k].append(recall)\n",
    "            f1_at_k[k].append(f1)\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    print(\"\\n----- EVALUATION RESULTS -----\")\n",
    "    for k in top_n_values:\n",
    "        if not precision_at_k[k]:\n",
    "            print(f\"No data for k={k}\")\n",
    "            continue\n",
    "            \n",
    "        avg_precision = np.mean(precision_at_k[k])\n",
    "        avg_recall = np.mean(recall_at_k[k])\n",
    "        avg_f1 = np.mean(f1_at_k[k])\n",
    "        \n",
    "        print(f\"\\nMetrics at k={k}:\")\n",
    "        print(f\"Precision@{k}: {avg_precision:.4f}\")\n",
    "        print(f\"Recall@{k}: {avg_recall:.4f}\")\n",
    "        print(f\"F1@{k}: {avg_f1:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'precision': precision_at_k,\n",
    "        'recall': recall_at_k,\n",
    "        'f1': f1_at_k\n",
    "    }\n",
    "\n",
    "# You can call this function to evaluate all test users\n",
    "metrics = evaluate_recommendations(top_n_values=[2, 5, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e52aaed-fe62-4903-b615-1f81d5ebe903",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
